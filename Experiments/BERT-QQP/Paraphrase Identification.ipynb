{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.18.5 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.18.5)\n",
      "Requirement already satisfied: matplotlib==3.2.2 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (3.2.2)\n",
      "Requirement already satisfied: pandas==1.0.5 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.0.5)\n",
      "Requirement already satisfied: tqdm==4.47.0 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (4.47.0)\n",
      "Requirement already satisfied: scikit-learn==0.23.1 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (0.23.1)\n",
      "Requirement already satisfied: data-science-utils==1.6.3 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (1.6.3)\n",
      "Requirement already satisfied: torch==1.4.0 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (1.4.0)\n",
      "Requirement already satisfied: transformers==3.0.2 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (3.0.2)\n",
      "Requirement already satisfied: notebook==6.1.5 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (6.1.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.2->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.2->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.2->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.2->-r requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from pandas==1.0.5->-r requirements.txt (line 3)) (2020.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from scikit-learn==0.23.1->-r requirements.txt (line 5)) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from scikit-learn==0.23.1->-r requirements.txt (line 5)) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from scikit-learn==0.23.1->-r requirements.txt (line 5)) (0.17.0)\n",
      "Requirement already satisfied: seaborn>=0.8.0 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from data-science-utils==1.6.3->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: pydotplus>=2.0.2 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from data-science-utils==1.6.3->-r requirements.txt (line 6)) (2.0.2)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from transformers==3.0.2->-r requirements.txt (line 8)) (0.8.1rc1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from transformers==3.0.2->-r requirements.txt (line 8)) (0.1.91)\n",
      "Requirement already satisfied: sacremoses in /Users/vishal/anaconda3/lib/python3.7/site-packages (from transformers==3.0.2->-r requirements.txt (line 8)) (0.0.49)\n",
      "Requirement already satisfied: filelock in /Users/vishal/anaconda3/lib/python3.7/site-packages (from transformers==3.0.2->-r requirements.txt (line 8)) (3.0.12)\n",
      "Requirement already satisfied: packaging in /Users/vishal/anaconda3/lib/python3.7/site-packages (from transformers==3.0.2->-r requirements.txt (line 8)) (21.3)\n",
      "Requirement already satisfied: requests in /Users/vishal/anaconda3/lib/python3.7/site-packages (from transformers==3.0.2->-r requirements.txt (line 8)) (2.24.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from transformers==3.0.2->-r requirements.txt (line 8)) (2021.8.3)\n",
      "Requirement already satisfied: ipython-genutils in /Users/vishal/anaconda3/lib/python3.7/site-packages (from notebook==6.1.5->-r requirements.txt (line 9)) (0.2.0)\n",
      "Requirement already satisfied: argon2-cffi in /Users/vishal/anaconda3/lib/python3.7/site-packages (from notebook==6.1.5->-r requirements.txt (line 9)) (21.3.0)\n",
      "Requirement already satisfied: jinja2 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from notebook==6.1.5->-r requirements.txt (line 9)) (2.11.2)\n",
      "Requirement already satisfied: nbformat in /Users/vishal/anaconda3/lib/python3.7/site-packages (from notebook==6.1.5->-r requirements.txt (line 9)) (5.0.8)\n",
      "Requirement already satisfied: ipykernel in /Users/vishal/anaconda3/lib/python3.7/site-packages (from notebook==6.1.5->-r requirements.txt (line 9)) (6.2.0)\n",
      "Requirement already satisfied: tornado>=5.0 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from notebook==6.1.5->-r requirements.txt (line 9)) (6.1)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from notebook==6.1.5->-r requirements.txt (line 9)) (5.0.5)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from notebook==6.1.5->-r requirements.txt (line 9)) (4.7.1)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from notebook==6.1.5->-r requirements.txt (line 9)) (6.1.7)\n",
      "Requirement already satisfied: Send2Trash in /Users/vishal/anaconda3/lib/python3.7/site-packages (from notebook==6.1.5->-r requirements.txt (line 9)) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from notebook==6.1.5->-r requirements.txt (line 9)) (0.9.4)\n",
      "Requirement already satisfied: nbconvert in /Users/vishal/anaconda3/lib/python3.7/site-packages (from notebook==6.1.5->-r requirements.txt (line 9)) (6.1.0)\n",
      "Requirement already satisfied: prometheus-client in /Users/vishal/anaconda3/lib/python3.7/site-packages (from notebook==6.1.5->-r requirements.txt (line 9)) (0.8.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from notebook==6.1.5->-r requirements.txt (line 9)) (20.0.0)\n",
      "Requirement already satisfied: six in /Users/vishal/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib==3.2.2->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: ptyprocess in /Users/vishal/anaconda3/lib/python3.7/site-packages (from terminado>=0.8.3->notebook==6.1.5->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/vishal/anaconda3/lib/python3.7/site-packages (from argon2-cffi->notebook==6.1.5->-r requirements.txt (line 9)) (21.2.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/vishal/anaconda3/lib/python3.7/site-packages (from argon2-cffi->notebook==6.1.5->-r requirements.txt (line 9)) (3.7.4.3)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.1.5->-r requirements.txt (line 9)) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /Users/vishal/anaconda3/lib/python3.7/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.1.5->-r requirements.txt (line 9)) (2.20)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (1.4.1)\n",
      "Requirement already satisfied: ipython<8.0,>=7.23.1 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (7.26.0)\n",
      "Requirement already satisfied: appnope in /Users/vishal/anaconda3/lib/python3.7/site-packages (from ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (0.1.2)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (0.1.2)\n",
      "Requirement already satisfied: argcomplete>=1.12.3 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (1.12.3)\n",
      "Requirement already satisfied: importlib-metadata<5 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (4.8.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from importlib-metadata<5->ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (3.4.0)\n",
      "Requirement already satisfied: backcall in /Users/vishal/anaconda3/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (52.0.0.post20210125)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (3.0.8)\n",
      "Requirement already satisfied: pygments in /Users/vishal/anaconda3/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (2.7.2)\n",
      "Requirement already satisfied: decorator in /Users/vishal/anaconda3/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /Users/vishal/anaconda3/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (0.17.2)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/vishal/anaconda3/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0,>=7.23.1->ipykernel->notebook==6.1.5->-r requirements.txt (line 9)) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from jinja2->notebook==6.1.5->-r requirements.txt (line 9)) (2.0.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook==6.1.5->-r requirements.txt (line 9)) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook==6.1.5->-r requirements.txt (line 9)) (0.5.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/vishal/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook==6.1.5->-r requirements.txt (line 9)) (0.1.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook==6.1.5->-r requirements.txt (line 9)) (0.3)\n",
      "Requirement already satisfied: bleach in /Users/vishal/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook==6.1.5->-r requirements.txt (line 9)) (3.2.1)\n",
      "Requirement already satisfied: defusedxml in /Users/vishal/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook==6.1.5->-r requirements.txt (line 9)) (0.6.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook==6.1.5->-r requirements.txt (line 9)) (1.4.3)\n",
      "Requirement already satisfied: testpath in /Users/vishal/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook==6.1.5->-r requirements.txt (line 9)) (0.4.4)\n",
      "Requirement already satisfied: async-generator in /Users/vishal/anaconda3/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook==6.1.5->-r requirements.txt (line 9)) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /Users/vishal/anaconda3/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook==6.1.5->-r requirements.txt (line 9)) (1.4.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from nbformat->notebook==6.1.5->-r requirements.txt (line 9)) (3.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook==6.1.5->-r requirements.txt (line 9)) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook==6.1.5->-r requirements.txt (line 9)) (20.3.0)\n",
      "Requirement already satisfied: webencodings in /Users/vishal/anaconda3/lib/python3.7/site-packages (from bleach->nbconvert->notebook==6.1.5->-r requirements.txt (line 9)) (0.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from requests->transformers==3.0.2->-r requirements.txt (line 8)) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from requests->transformers==3.0.2->-r requirements.txt (line 8)) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from requests->transformers==3.0.2->-r requirements.txt (line 8)) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/vishal/anaconda3/lib/python3.7/site-packages (from requests->transformers==3.0.2->-r requirements.txt (line 8)) (3.0.4)\n",
      "Requirement already satisfied: click in /Users/vishal/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2->-r requirements.txt (line 8)) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid1  qid2                                          question1  \\\n",
       "id                                                                  \n",
       "0      1     2  What is the step by step guide to invest in sh...   \n",
       "1      3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2      5     6  How can I increase the speed of my internet co...   \n",
       "3      7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4      9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                            question2  is_duplicate  \n",
       "id                                                                   \n",
       "0   What is the step by step guide to invest in sh...             0  \n",
       "1   What would happen if the Indian government sto...             0  \n",
       "2   How can Internet speed be increased by hacking...             0  \n",
       "3   Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4             Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "qqp_df = pandas.read_csv(\"train.csv\", index_col=\"id\", nrows=5000)\n",
    "qqp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   qid1          5000 non-null   int64 \n",
      " 1   qid2          5000 non-null   int64 \n",
      " 2   question1     5000 non-null   object\n",
      " 3   question2     5000 non-null   object\n",
      " 4   is_duplicate  5000 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 234.4+ KB\n"
     ]
    }
   ],
   "source": [
    "qqp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishal/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/vishal/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/vishal/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/vishal/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/vishal/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/vishal/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/vishal/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/vishal/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/vishal/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/vishal/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/vishal/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/vishal/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9d090c224f4cd0b61b5d876e162498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True, return_dict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: What is the step by step guide to invest in share market in india?\n",
      "Tokenized: ['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market', 'in', 'india', '?']\n",
      "Token IDs: [2054, 2003, 1996, 3357, 2011, 3357, 5009, 2000, 15697, 1999, 3745, 3006, 1999, 2634, 1029]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original: {qqp_df['question1'][0]}\")\n",
    "print(f\"Tokenized: {tokenizer.tokenize(qqp_df['question1'][0])}\")\n",
    "print(f\"Token IDs: {tokenizer.convert_tokens_to_ids(tokenizer.tokenize(qqp_df['question1'][0]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] what is the step by step guide to invest in share market in india? [SEP] what is the step by step guide to invest in share market? [SEP]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_pair = tokenizer.encode(qqp_df['question1'][0], qqp_df['question2'][0])\n",
    "tokenizer.decode(encoded_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>Is there a way to get a user's friends' email ...</td>\n",
       "      <td>Is there any way to get a user's email address...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>How can I get rid of cellulite on my stomach?</td>\n",
       "      <td>I am in good shape but have a trouble spot of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>Among SC, ST, NC and OBC which is the lowest c...</td>\n",
       "      <td>Is the 'Tili' caste in West Bengal SC/ST/OBC?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>Are you tolerant if you tolerate the intolerant?</td>\n",
       "      <td>Are you tolerant?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>Are food allergies more common in USA?</td>\n",
       "      <td>Why are food allergies so common in USA?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question1  \\\n",
       "id                                                        \n",
       "3444  Is there a way to get a user's friends' email ...   \n",
       "2063      How can I get rid of cellulite on my stomach?   \n",
       "3714  Among SC, ST, NC and OBC which is the lowest c...   \n",
       "2671   Are you tolerant if you tolerate the intolerant?   \n",
       "2154             Are food allergies more common in USA?   \n",
       "\n",
       "                                              question2  \n",
       "id                                                       \n",
       "3444  Is there any way to get a user's email address...  \n",
       "2063  I am in good shape but have a trouble spot of ...  \n",
       "3714      Is the 'Tili' caste in West Bengal SC/ST/OBC?  \n",
       "2671                                  Are you tolerant?  \n",
       "2154           Why are food allergies so common in USA?  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(qqp_df[[\"question1\", \"question2\"]], \n",
    "                                                    qqp_df[\"is_duplicate\"], test_size=0.2, random_state=42)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2003,  2045,  1037,  2126,  2000,  2131,  1037,  5310,  1005,\n",
       "          1055,  2814,  1005, 10373,  4769,  2083,  9130, 17928,  2005, 25718,\n",
       "          1029,   102,  2003,  2045,  2151,  2126,  2000,  2131,  1037,  5310,\n",
       "          1005,  1055, 10373,  4769,  2083, 10474,  1051,  4887,  2705, 17928,\n",
       "          1029,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 310\n",
    "tokenizer.encode_plus(X_train.iloc[0][\"question1\"], X_train.iloc[0][\"question2\"], max_length=max_length, \n",
    "                      pad_to_max_length=True, return_attention_mask=True, return_tensors='pt', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "def convert_to_dataset_torch(data: pandas.DataFrame, labels: pandas.Series) -> TensorDataset:\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    "    for _, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        encoded_dict = tokenizer.encode_plus(row[\"question1\"], row[\"question2\"], max_length=max_length, pad_to_max_length=True, \n",
    "                      return_attention_mask=True, return_tensors='pt', truncation=True)\n",
    "        # Add the encoded sentences to the list.\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        token_type_ids.append(encoded_dict[\"token_type_ids\"])\n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    token_type_ids = torch.cat(token_type_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels.values)\n",
    "    \n",
    "    return TensorDataset(input_ids, attention_masks, token_type_ids, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3200/3200 [00:01<00:00, 2284.13it/s]\n",
      "100%|███████████████████████████████████████| 800/800 [00:00<00:00, 2428.91it/s]\n"
     ]
    }
   ],
   "source": [
    "train = convert_to_dataset_torch(X_train, y_train)\n",
    "validation = convert_to_dataset_torch(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "core_number = multiprocessing.cpu_count()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train, \n",
    "            sampler = RandomSampler(train), \n",
    "            batch_size = batch_size,\n",
    "            num_workers = core_number\n",
    "        )\n",
    "validation_dataloader = DataLoader(\n",
    "            validation,\n",
    "            sampler = SequentialSampler(validation), \n",
    "            batch_size = batch_size,\n",
    "            num_workers = core_number\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "bert_model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Using the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels=2,  \n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "adamw_optimizer = AdamW(bert_model.parameters(),\n",
    "                  lr = 2e-5,\n",
    "                  eps = 1e-8 \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(adamw_optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_batch(dataloader, model, optimizer, epoch):\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=f\"Training epoch:{epoch}\", unit=\"batch\"):\n",
    "        input_ids, attention_masks, token_type_ids, labels = batch\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        loss, _ = model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_masks, labels=labels)\n",
    "        total_train_loss = total_train_loss + loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "    return total_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def eval_batch(dataloader, model, metric=accuracy_score):\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    predictions , predicted_labels = [], []\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "        input_ids, attention_masks, token_type_ids, labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            loss, logits = model(input_ids, \n",
    "                                   token_type_ids=token_type_ids, \n",
    "                                   attention_mask=attention_masks,\n",
    "                                   labels=labels)\n",
    "        total_eval_loss = total_eval_loss + loss.item()\n",
    "\n",
    "        y_pred = numpy.argmax(logits.detach().numpy(), axis=1).flatten()\n",
    "        total_eval_accuracy = total_eval_accuracy + metric(labels, y_pred)\n",
    "        \n",
    "        predictions.extend(logits.detach().numpy().tolist())\n",
    "        predicted_labels.extend(y_pred.tolist())\n",
    "    \n",
    "    return total_eval_accuracy, total_eval_loss, predictions ,predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "numpy.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "\n",
    "\n",
    "def train(train_dataloader, validation_dataloader, model, optimizer, epochs):\n",
    "    #for storing accuracy, etc.\n",
    "    training_stats = []\n",
    "    \n",
    "    # Measure the total training time for the whole run.\n",
    "    total_t0 = time.time()\n",
    "    \n",
    "    for epoch in range(0, epochs):\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        total_train_loss = 0\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        total_train_loss = fit_batch(train_dataloader, model, optimizer, epoch)\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "        training_time = format_time(time.time() - t0)\n",
    "        \n",
    "        t0 = time.time()\n",
    "\n",
    "        model.eval()\n",
    "        \n",
    "        total_eval_accuracy, total_eval_loss, _, _ = eval_batch(validation_dataloader, model)\n",
    "\n",
    "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "        \n",
    "        print(f\"  Accuracy: {avg_val_accuracy}\")\n",
    "\n",
    "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "        validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "        print(f\"  Validation Loss: {avg_val_loss}\")\n",
    "    \n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Valid. Loss': avg_val_loss,\n",
    "                'Valid. Accur.': avg_val_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "        \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    print(f\"Total training took {format_time(time.time()-total_t0)}\")\n",
    "    return training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch:0:   0%|                              | 0/100 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:0: 100%|██████████████████| 100/100 [1:28:07<00:00, 51.56s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:0: 100%|██████████████████| 100/100 [1:28:07<00:00, 52.88s/batch]\n",
      "Evaluating:   0%|                                     | 0/25 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "To disable this warning, you can either:\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████| 25/25 [04:11<00:00,  9.98s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████| 25/25 [04:11<00:00, 10.05s/batch]\n",
      "Training epoch:1:   0%|                              | 0/100 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.7325\n",
      "  Validation Loss: 0.48477966904640196\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:1: 100%|██████████████████| 100/100 [1:18:45<00:00, 46.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:1: 100%|██████████████████| 100/100 [1:18:45<00:00, 47.25s/batch]\n",
      "Evaluating:   0%|                                     | 0/25 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████| 25/25 [04:09<00:00,  9.99s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating: 100%|████████████████████████████| 25/25 [04:09<00:00,  9.99s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.78125\n",
      "  Validation Loss: 0.4441431283950806\n",
      "\n",
      "Training complete!\n",
      "Total training took 2:55:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_stats = train(train_dataloader, validation_dataloader, bert_model, adamw_optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.555946</td>\n",
       "      <td>0.484780</td>\n",
       "      <td>0.73250</td>\n",
       "      <td>1:28:08</td>\n",
       "      <td>0:04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.418284</td>\n",
       "      <td>0.444143</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>1:18:45</td>\n",
       "      <td>0:04:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "0           0.555946     0.484780        0.73250       1:28:08         0:04:11\n",
       "1           0.418284     0.444143        0.78125       1:18:45         0:04:10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats = pandas.DataFrame(training_stats).set_index('epoch')\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pyplot.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "pyplot.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "pyplot.title(\"Training & Validation Loss\")\n",
    "pyplot.xlabel(\"Epoch\")\n",
    "pyplot.ylabel(\"Loss\")\n",
    "pyplot.legend()\n",
    "pyplot.xticks(df_stats.index.values.tolist())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 2108.51it/s]\n"
     ]
    }
   ],
   "source": [
    "test = convert_to_dataset_torch(X_test, y_test)\n",
    "test_dataloader = DataLoader(test,  sampler=SequentialSampler(test), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████| 32/32 [05:30<00:00, 10.33s/batch]\n"
     ]
    }
   ],
   "source": [
    "bert_model.eval()\n",
    "_, _,_ ,predicted_labels = eval_batch(test_dataloader, bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ds_utils.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(y_test, predicted_labels, [1, 0])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
